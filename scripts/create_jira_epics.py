#!/usr/bin/env python3
"""
Script para crear Epics y Stories en Jira desde el documento de requerimientos
Estructura completa de HAIDA v2.0
"""

import os
import time
from atlassian import Jira
from dotenv import load_dotenv

# Configuraci√≥n Jira
load_dotenv()

JIRA_URL = os.getenv("ATLASSIAN_URL")
JIRA_EMAIL = os.getenv("ATLASSIAN_EMAIL")
JIRA_TOKEN = os.getenv("ATLASSIAN_API_TOKEN")
PROJECT_KEY = os.getenv("JIRA_PROJECT_KEY", "HAIDA")

if not JIRA_URL or not JIRA_EMAIL or not JIRA_TOKEN:
    raise SystemExit("Missing ATLASSIAN_URL/ATLASSIAN_EMAIL/ATLASSIAN_API_TOKEN environment variables.")

# Inicializar cliente Jira
jira = Jira(
    url=JIRA_URL,
    username=JIRA_EMAIL,
    password=JIRA_TOKEN,
    cloud=True
)

# Estructura de Epics y Stories
EPICS_AND_STORIES = [
    {
        "epic": {
            "summary": "√âPICA 1: BACKEND API (FastAPI)",
            "description": """
Desarrollo completo del backend API REST con FastAPI.
Incluye autenticaci√≥n JWT, routers modulares, integraci√≥n con base de datos.

**Componentes**:
- 7 routers REST (auth, tests, reports, jira, confluence, ai, health)
- Sistema de autenticaci√≥n JWT
- Middleware CORS y seguridad
- Documentaci√≥n Swagger autom√°tica
- Integraci√≥n con PostgreSQL/Supabase

**M√©tricas Objetivo**:
- 23 endpoints REST funcionales
- < 200ms tiempo de respuesta promedio
- 99.9% uptime
- Rate limiting configurado
            """,
            "priority": "Highest"
        },
        "stories": [
            {
                "summary": "Sistema de Autenticaci√≥n JWT",
                "description": """
**Objetivo**: Implementar autenticaci√≥n completa con JWT tokens.

**Criterios de Aceptaci√≥n**:
- ‚úÖ Endpoint POST /api/auth/login con email/password
- ‚úÖ Generaci√≥n de tokens JWT con expiraci√≥n de 30 minutos
- ‚úÖ Passwords hasheados con bcrypt (12 salt rounds)
- ‚úÖ Endpoint POST /api/auth/register para nuevos usuarios
- ‚úÖ Endpoint GET /api/auth/me para obtener usuario actual
- ‚úÖ Endpoint POST /api/auth/refresh para renovar token
- ‚úÖ Endpoint POST /api/auth/logout para invalidar token

**Implementaci√≥n**:
- Archivo: `app/routers/auth.py`
- Dependencias: python-jose[cryptography], passlib[bcrypt]
- Config: JWT_SECRET, JWT_ALGORITHM, JWT_EXPIRATION_MINUTES en .env

**DoD**:
- ‚úÖ Tests unitarios > 80% coverage
- ‚úÖ Documentaci√≥n Swagger completa
- ‚úÖ Manejo de errores 401/403 adecuado
- ‚úÖ Rate limiting: 5 intentos/minuto por IP
                """,
                "priority": "Highest",
                "story_points": 8,
                "labels": ["backend", "auth", "security"]
            },
            {
                "summary": "Router de Tests - CRUD y Ejecuci√≥n",
                "description": """
**Objetivo**: Gesti√≥n completa de test suites y ejecuciones.

**Criterios de Aceptaci√≥n**:
- ‚úÖ GET /api/tests - Listar todas las test suites del proyecto
- ‚úÖ POST /api/tests - Crear nueva test suite
- ‚úÖ GET /api/tests/{id} - Obtener detalles de una suite
- ‚úÖ PUT /api/tests/{id} - Actualizar suite
- ‚úÖ DELETE /api/tests/{id} - Eliminar suite
- ‚úÖ POST /api/tests/run - Ejecutar suite (async con Celery)
- ‚úÖ GET /api/tests/executions - Historial de ejecuciones

**Implementaci√≥n**:
- Archivo: `app/routers/tests.py`
- Integraci√≥n con: Playwright, Newman, k6, Lighthouse
- Queue: Celery + Redis para ejecuciones async

**DoD**:
- ‚úÖ Ejecutar tests en background (no bloquear API)
- ‚úÖ Webhooks para notificar fin de ejecuci√≥n
- ‚úÖ Logs de ejecuci√≥n guardados en BD
                """,
                "priority": "High",
                "story_points": 13,
                "labels": ["backend", "tests", "core"]
            },
            {
                "summary": "Router de Reports - Generaci√≥n y Consulta",
                "description": """
**Objetivo**: Sistema de reportes con Allure Framework.

**Criterios de Aceptaci√≥n**:
- ‚úÖ GET /api/reports - Listar reportes disponibles
- ‚úÖ POST /api/reports/generate - Generar reporte Allure
- ‚úÖ GET /api/reports/{id} - Descargar reporte (PDF/HTML)
- ‚úÖ GET /api/reports/trending - Datos hist√≥ricos para gr√°ficos

**Implementaci√≥n**:
- Archivo: `app/routers/reports.py`
- Allure CLI para generaci√≥n
- ReportLab para PDFs custom

**DoD**:
- ‚úÖ Reportes generados en < 5 segundos
- ‚úÖ Storage en S3 o filesystem con cleanup autom√°tico
                """,
                "priority": "Medium",
                "story_points": 8,
                "labels": ["backend", "reports", "allure"]
            },
            {
                "summary": "Integraci√≥n Jira - Creaci√≥n Autom√°tica de Issues",
                "description": """
**Objetivo**: Crear tickets Jira autom√°ticamente cuando tests fallan.

**Criterios de Aceptaci√≥n**:
- ‚úÖ POST /api/jira/issues - Crear issue desde test failure
- ‚úÖ GET /api/jira/issues - Listar issues del proyecto HAIDA
- ‚úÖ PUT /api/jira/issues/{key} - Actualizar estado de issue
- ‚úÖ Mapping autom√°tico: Test ‚Üí Issue (tabla jira_issues)

**Implementaci√≥n**:
- Archivo: `app/routers/jira.py`
- Librer√≠a: atlassian-python-api
- Plantilla de issue: bug, test-failure, automated

**DoD**:
- ‚úÖ Issues creados con screenshot adjunto
- ‚úÖ Descripci√≥n incluye: pasos para reproducir, logs, stack trace
                """,
                "priority": "High",
                "story_points": 8,
                "labels": ["backend", "jira", "integration"]
            },
            {
                "summary": "Integraci√≥n Confluence - Documentaci√≥n Autom√°tica",
                "description": """
**Objetivo**: Publicar resultados de tests en Confluence autom√°ticamente.

**Criterios de Aceptaci√≥n**:
- ‚úÖ POST /api/confluence/pages - Crear p√°gina con resultados
- ‚úÖ GET /api/confluence/pages - Listar p√°ginas del espacio HAIDA
- ‚úÖ PUT /api/confluence/pages/{id} - Actualizar p√°gina existente

**Implementaci√≥n**:
- Archivo: `app/routers/confluence.py`
- Template HTML para p√°ginas de resultados
- Gr√°ficos de trending embebidos

**DoD**:
- ‚úÖ P√°ginas creadas con formato profesional
- ‚úÖ Tablas de resultados con colores (rojo/verde)
                """,
                "priority": "Medium",
                "story_points": 5,
                "labels": ["backend", "confluence", "docs"]
            },
            {
                "summary": "Router de IA - Chat con DeepSeek R1",
                "description": """
**Objetivo**: Integrar DeepSeek R1 para asistencia inteligente.

**Criterios de Aceptaci√≥n**:
- ‚úÖ POST /api/ai/chat - Enviar mensaje y recibir respuesta
- ‚úÖ GET /api/ai/chats - Historial de conversaciones
- ‚úÖ POST /api/ai/generate-tests - Generar test cases desde spec

**Implementaci√≥n**:
- Archivo: `app/routers/ai.py`
- Cliente: LM Studio API (compatible OpenAI)
- Modelo: DeepSeek-R1-0528-Qwen3-8B

**DoD**:
- ‚úÖ Respuestas en < 5 segundos
- ‚úÖ Context preservation (√∫ltimos 10 mensajes)
                """,
                "priority": "Medium",
                "story_points": 8,
                "labels": ["backend", "ai", "deepseek"]
            },
            {
                "summary": "Health Checks y Monitoreo",
                "description": """
**Objetivo**: Endpoints de salud para monitoreo y alertas.

**Criterios de Aceptaci√≥n**:
- ‚úÖ GET /health - Health check b√°sico (200 OK)
- ‚úÖ GET /status - Estado detallado de servicios
- ‚úÖ GET /metrics - M√©tricas Prometheus (opcional)

**Implementaci√≥n**:
- Archivo: `app/routers/health.py`
- Checks: DB, Redis, LM Studio, Jira, Confluence

**DoD**:
- ‚úÖ Response time < 100ms
- ‚úÖ Integraci√≥n con Railway health checks
                """,
                "priority": "High",
                "story_points": 3,
                "labels": ["backend", "monitoring", "devops"]
            }
        ]
    },
    {
        "epic": {
            "summary": "√âPICA 2: BASE DE DATOS (Supabase PostgreSQL)",
            "description": """
Dise√±o e implementaci√≥n del schema de base de datos con seguridad RLS.

**Componentes**:
- 7 tablas relacionales
- 10 √≠ndices optimizados
- 10 pol√≠ticas Row Level Security (RLS)
- 4 usuarios demo
- Triggers autom√°ticos

**Stack**:
- PostgreSQL 15 (Supabase)
- SQLAlchemy 2.0 ORM
- Alembic para migraciones
            """,
            "priority": "Highest"
        },
        "stories": [
            {
                "summary": "Dise√±o de Schema y Migraciones",
                "description": """
**Objetivo**: Schema completo con todas las tablas y relaciones.

**Tablas**:
1. users (autenticaci√≥n, roles)
2. projects (multi-tenant)
3. test_suites (tipos, configuraci√≥n)
4. test_executions (resultados, logs)
5. reports (PDF, HTML)
6. jira_issues (mapping)
7. ai_chats (historial IA)

**DoD**:
- ‚úÖ Archivo database_schema.sql funcional
- ‚úÖ Migraciones Alembic creadas
- ‚úÖ Seed data con 4 usuarios demo
                """,
                "priority": "Highest",
                "story_points": 13,
                "labels": ["database", "schema", "postgresql"]
            },
            {
                "summary": "Row Level Security (RLS) y Multi-tenancy",
                "description": """
**Objetivo**: Seguridad a nivel de fila para aislamiento de datos.

**Pol√≠ticas RLS**:
- Users solo ven sus propios datos
- Projects aislados por owner
- Test suites visibles solo para miembros del proyecto

**DoD**:
- ‚úÖ 10 pol√≠ticas RLS creadas y testeadas
- ‚úÖ Admin puede ver todo
- ‚úÖ Viewers solo lectura
                """,
                "priority": "High",
                "story_points": 8,
                "labels": ["database", "security", "rls"]
            },
            {
                "summary": "√çndices y Optimizaci√≥n de Performance",
                "description": """
**Objetivo**: Queries r√°pidas con √≠ndices adecuados.

**√çndices**:
- users.email (UNIQUE)
- test_executions.test_suite_id + created_at (composite)
- jira_issues.test_execution_id

**DoD**:
- ‚úÖ Queries < 50ms en promedio
- ‚úÖ EXPLAIN ANALYZE ejecutado en queries cr√≠ticas
                """,
                "priority": "Medium",
                "story_points": 5,
                "labels": ["database", "performance", "optimization"]
            }
        ]
    },
    {
        "epic": {
            "summary": "√âPICA 3: TELEGRAM BOT 24/7",
            "description": """
Bot de Telegram con MiniApp para gesti√≥n de HAIDA desde chat.

**Funcionalidades**:
- Dashboard MiniApp embebida
- Comandos: /start, /status, /tests, /reports, /help
- Inline mode para b√∫squedas
- Callback handlers para botones
- Deploy 24/7 en Railway

**Stack**:
- python-telegram-bot 20.7
- Async handlers
- Webhook mode (Railway)
            """,
            "priority": "High"
        },
        "stories": [
            {
                "summary": "Bot Core - Comandos y Handlers",
                "description": """
**Objetivo**: Bot funcional con todos los comandos principales.

**Comandos**:
- /start ‚Üí Men√∫ principal con botones
- /status ‚Üí Health check de servicios
- /tests ‚Üí Listar y ejecutar test suites
- /reports ‚Üí Ver √∫ltimos reportes
- /help ‚Üí Ayuda y documentaci√≥n

**DoD**:
- ‚úÖ 243 l√≠neas de c√≥digo funcionando
- ‚úÖ Error handling para comandos inv√°lidos
                """,
                "priority": "High",
                "story_points": 8,
                "labels": ["telegram", "bot", "core"]
            },
            {
                "summary": "MiniApp Web Embebida",
                "description": """
**Objetivo**: Dashboard web dentro de Telegram.

**Features**:
- Ver gr√°ficos de trending
- Ejecutar tests con configuraci√≥n avanzada
- Descargar reportes PDF

**DoD**:
- ‚úÖ MiniApp funciona en Telegram iOS y Android
- ‚úÖ Autenticaci√≥n con Telegram user ID
                """,
                "priority": "Medium",
                "story_points": 13,
                "labels": ["telegram", "miniapp", "web"]
            },
            {
                "summary": "Deploy Railway 24/7",
                "description": """
**Objetivo**: Bot siempre online en Railway.

**Configuraci√≥n**:
- Webhook mode (no polling)
- Health checks configurados
- Auto-restart en fallos
- Logs centralizados

**DoD**:
- ‚úÖ Uptime > 99.5%
- ‚úÖ Response time < 500ms
                """,
                "priority": "High",
                "story_points": 5,
                "labels": ["telegram", "deploy", "railway"]
            }
        ]
    },
    {
        "epic": {
            "summary": "√âPICA 4: TESTING AUTOMATIZADO MULTI-NIVEL",
            "description": """
Framework de testing completo con 4 niveles:
- E2E Web (Playwright)
- API (Newman)
- Performance (k6)
- Accessibility (Lighthouse)

**Objetivo**: Cobertura 95%+ con est√°ndares ISTQB.

**Frameworks**:
- Playwright 1.41
- Newman 6.0
- k6 latest
- Lighthouse 12.0
            """,
            "priority": "Highest"
        },
        "stories": [
            {
                "summary": "Tests E2E Web con Playwright",
                "description": """
**Objetivo**: Suite completa de tests E2E multi-navegador.

**Features**:
- Tests en Chrome, Firefox, Safari, Edge
- Screenshots + videos autom√°ticos en fallos
- Paralelizaci√≥n (4 workers)
- Retry autom√°tico (1 retry)

**DoD**:
- ‚úÖ > 50 tests E2E creados
- ‚úÖ Ejecuci√≥n completa en < 3 minutos
                """,
                "priority": "Highest",
                "story_points": 21,
                "labels": ["testing", "e2e", "playwright"]
            },
            {
                "summary": "Tests API con Newman/Postman",
                "description": """
**Objetivo**: Validaci√≥n completa de API REST.

**Collections**:
- Auth endpoints
- Tests CRUD
- Reports endpoints
- Jira/Confluence integration

**DoD**:
- ‚úÖ > 100 assertions API
- ‚úÖ Environments: dev, qa, prod
                """,
                "priority": "High",
                "story_points": 13,
                "labels": ["testing", "api", "newman"]
            },
            {
                "summary": "Tests de Performance con k6",
                "description": """
**Objetivo**: Validar performance bajo carga.

**Escenarios**:
- Load testing (100 usuarios concurrentes)
- Stress testing (identificar l√≠mite)
- Spike testing (picos de tr√°fico)

**DoD**:
- ‚úÖ Response time < 200ms (p95)
- ‚úÖ Throughput > 1000 req/s
                """,
                "priority": "Medium",
                "story_points": 8,
                "labels": ["testing", "performance", "k6"]
            },
            {
                "summary": "Auditor√≠as de Accesibilidad con Lighthouse",
                "description": """
**Objetivo**: Compliance WCAG 2.0 AA.

**Auditor√≠as**:
- Accessibility score > 90
- Performance score > 85
- Best practices score > 90
- SEO score > 85

**DoD**:
- ‚úÖ Auditor√≠as autom√°ticas en CI/CD
- ‚úÖ Reportes HTML generados
                """,
                "priority": "Medium",
                "story_points": 5,
                "labels": ["testing", "accessibility", "lighthouse"]
            }
        ]
    },
    {
        "epic": {
            "summary": "√âPICA 5: DEVOPS & INFRAESTRUCTURA",
            "description": """
Infraestructura completa con Docker, CI/CD y deployment.

**Componentes**:
- Docker Compose (7 servicios)
- GitHub Actions CI/CD
- Railway deployment
- Monitoring y logging

**Objetivo**: Zero-downtime deployments, scaling autom√°tico.
            """,
            "priority": "High"
        },
        "stories": [
            {
                "summary": "Docker Compose - Entorno Local",
                "description": """
**Objetivo**: Levantar stack completo con un comando.

**Servicios**:
1. api (FastAPI)
2. postgres (BD)
3. redis (cache)
4. bot (Telegram)
5. playwright (runner)
6. newman (runner)
7. allure (reportes)

**DoD**:
- ‚úÖ `docker-compose up -d` funciona
- ‚úÖ Health checks para todos los servicios
                """,
                "priority": "High",
                "story_points": 13,
                "labels": ["devops", "docker", "local"]
            },
            {
                "summary": "CI/CD GitHub Actions",
                "description": """
**Objetivo**: Pipeline completo de CI/CD.

**Stages**:
1. Lint (flake8, black)
2. Tests (pytest)
3. Build (Docker image)
4. Deploy (Railway)

**DoD**:
- ‚úÖ Tests corriendo en cada PR
- ‚úÖ Deploy autom√°tico a Railway en merge a main
                """,
                "priority": "High",
                "story_points": 8,
                "labels": ["devops", "cicd", "github-actions"]
            },
            {
                "summary": "Deployment Railway - API + Bot",
                "description": """
**Objetivo**: Deploy productivo en Railway.

**Configuraci√≥n**:
- API: Web service (https://haida-api.railway.app)
- Bot: Worker process (24/7)
- Variables de entorno desde Railway UI
- Logs centralizados

**DoD**:
- ‚úÖ Uptime > 99.5%
- ‚úÖ Auto-scaling configurado
                """,
                "priority": "Highest",
                "story_points": 8,
                "labels": ["devops", "deploy", "railway"]
            }
        ]
    },
    {
        "epic": {
            "summary": "√âPICA 6: REPORTING & ANALYTICS",
            "description": """
Sistema de reportes con Allure Framework y dashboards.

**Features**:
- Reportes HTML unificados
- Trending hist√≥rico
- Exportaci√≥n PDF
- Dashboards con gr√°ficos

**Stack**:
- Allure Framework 2.0
- ReportLab para PDFs
- Chart.js para gr√°ficos
            """,
            "priority": "Medium"
        },
        "stories": [
            {
                "summary": "Allure Framework - Reportes Unificados",
                "description": """
**Objetivo**: Reportes HTML profesionales con Allure.

**Features**:
- Resultados de Playwright, Newman, k6, Lighthouse
- Screenshots y videos embebidos
- Logs y stack traces
- Trending hist√≥rico (√∫ltimos 30 d√≠as)

**DoD**:
- ‚úÖ Reportes generados en < 5 segundos
- ‚úÖ Servidor Allure corriendo en Docker
                """,
                "priority": "Medium",
                "story_points": 13,
                "labels": ["reporting", "allure", "analytics"]
            }
        ]
    },
    {
        "epic": {
            "summary": "√âPICA 7: SEGURIDAD & COMPLIANCE",
            "description": """
Medidas de seguridad y compliance con est√°ndares.

**Features**:
- JWT authentication
- RLS en base de datos
- CORS configurado
- Rate limiting
- HTTPS obligatorio
- Audit logs
- GDPR compliance
- WCAG 2.0 AA

**Est√°ndares**:
- ISTQB (testing)
- WCAG 2.0 AA (accesibilidad)
- GDPR (privacidad)
            """,
            "priority": "Highest"
        },
        "stories": [
            {
                "summary": "Seguridad API - CORS, Rate Limiting, JWT",
                "description": """
**Objetivo**: API segura contra ataques comunes.

**Medidas**:
- CORS: Solo dominios autorizados
- Rate limiting: 100 req/min por IP
- JWT: Tokens con expiraci√≥n 30 min
- HTTPS: TLS 1.3 obligatorio

**DoD**:
- ‚úÖ Security headers configurados
- ‚úÖ OWASP Top 10 validado
                """,
                "priority": "Highest",
                "story_points": 8,
                "labels": ["security", "api", "cors"]
            },
            {
                "summary": "Compliance GDPR y Audit Logs",
                "description": """
**Objetivo**: Compliance con GDPR y trazabilidad.

**Features**:
- Audit logs en tabla audit_log
- GDPR: derecho al olvido (endpoint DELETE /api/auth/me)
- Encriptaci√≥n de datos sensibles
- Retention policy (logs 90 d√≠as)

**DoD**:
- ‚úÖ Todas las acciones cr√≠ticas logueadas
- ‚úÖ GDPR-compliant
                """,
                "priority": "High",
                "story_points": 5,
                "labels": ["security", "compliance", "gdpr"]
            }
        ]
    }
]

def create_epic(epic_data):
    """Crear un Epic (Task) en Jira"""
    try:
        # Usar Task en lugar de Epic (Epic no est√° habilitado en plan free)
        issue = jira.issue_create({
            "project": {"key": PROJECT_KEY},
            "summary": epic_data["summary"],
            "description": epic_data["description"],
            "issuetype": {"name": "Task"},  # Cambio: Task en lugar de Epic
            "priority": {"name": epic_data.get("priority", "Medium")},
            "labels": ["epic", "haida-v2"]  # Etiqueta para identificar como Epic
        })

        epic_key = issue["key"]
        print(f"‚úÖ Epic (Task) creado: {epic_key} - {epic_data['summary']}")
        return epic_key

    except Exception as e:
        print(f"‚ùå Error creando epic: {str(e)}")
        return None

def create_story(story_data, epic_key):
    """Crear una Story (Task) vinculada a un Epic"""
    try:
        # Preparar labels con el epic parent
        labels = story_data.get("labels", []) + ["story", "haida-v2"]
        if epic_key:
            labels.append(f"epic:{epic_key}")

        fields = {
            "project": {"key": PROJECT_KEY},
            "summary": story_data["summary"],
            "description": story_data["description"],
            "issuetype": {"name": "Task"},  # Cambio: Task en lugar de Story
            "priority": {"name": story_data.get("priority", "Medium")},
            "labels": labels
        }

        # En Jira Cloud free, parent puede no estar disponible
        # Usamos labels para linkear Epic ‚Üí Story

        issue = jira.issue_create(fields)

        story_key = issue["key"]
        print(f"   ‚úÖ Story (Task) creada: {story_key} - {story_data['summary']}")

        # Intentar crear link (puede fallar si no hay permisos)
        try:
            if epic_key:
                jira.issue_link_create({
                    "type": {"name": "Relates"},
                    "inwardIssue": {"key": story_key},
                    "outwardIssue": {"key": epic_key}
                })
                print(f"      üîó Vinculada a {epic_key}")
        except:
            pass  # Link opcional

        return story_key

    except Exception as e:
        print(f"   ‚ùå Error creando story: {str(e)}")
        return None

def main():
    print("üöÄ HAIDA - Creaci√≥n de Epics y Stories en Jira")
    print(f"üìç Proyecto: {PROJECT_KEY}")
    print(f"üåê URL: {JIRA_URL}")
    print("="*60)

    total_epics = 0
    total_stories = 0

    for item in EPICS_AND_STORIES:
        print(f"\nüì¶ {item['epic']['summary']}")

        # Crear Epic
        epic_key = create_epic(item["epic"])

        if epic_key:
            total_epics += 1

            # Crear Stories del Epic
            for story in item.get("stories", []):
                story_key = create_story(story, epic_key)

                if story_key:
                    total_stories += 1

                time.sleep(0.5)  # Evitar rate limiting

        time.sleep(1)

    # Resumen final
    print("\n" + "="*60)
    print("üìä RESUMEN:")
    print(f"   Epics creados: {total_epics}/{len(EPICS_AND_STORIES)}")
    print(f"   Stories creadas: {total_stories}")
    print(f"\n‚úÖ Proceso completado!")
    print(f"\nüåê Ver en Jira: {JIRA_URL}/browse/{PROJECT_KEY}")

if __name__ == "__main__":
    main()
